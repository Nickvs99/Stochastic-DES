{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic simulation assignment 2\n",
    "## Peter Voerman and Nick van Santen\n",
    "### 11749547 and 11857846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import simpy\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server():\n",
    "\n",
    "    def __init__(self, env, n_machines):\n",
    "        self.env = env\n",
    "        self.machine = simpy.PriorityResource(env, n_machines)\n",
    "\n",
    "    def run_task(self, waiting_time):\n",
    "        yield self.env.timeout(waiting_time)\n",
    "\n",
    "    @property\n",
    "    def queue_length(self):\n",
    "        return len(self.machine.queue)\n",
    "\n",
    "\n",
    "def process_task(env, server, data, waiting_times, duration, shortest_job_first, time_choice):\n",
    "    if time_choice == 'm':\n",
    "        waiting_time = generate_random_markov(duration)\n",
    "        if shortest_job_first:\n",
    "            bisect.insort(waiting_times, waiting_time)\n",
    "            index = (waiting_times.index(waiting_time))\n",
    "\n",
    "            for request in server.machine.queue:\n",
    "                if request.priority >= index:\n",
    "                    request.priority += 1\n",
    "        else:\n",
    "            index = 1\n",
    "            \n",
    "    elif time_choice == 'd':\n",
    "        waiting_time = duration\n",
    "        index = 1\n",
    "    \n",
    "\n",
    "    #print(f\"{task} added to server at {env.now}. Queue length: {server.queue_length}\")\n",
    "    time_at_queue = env.now\n",
    "    with server.machine.request(priority=index) as request:\n",
    "        yield request\n",
    "\n",
    "        #print(f\"{task} is being processed at {env.now}\")\n",
    "        time_start_process = env.now\n",
    "        yield env.process(server.run_task(waiting_time))\n",
    "        #print(f\"{task} is completed at {env.now}\")\n",
    "        time_end_process = env.now\n",
    "        \n",
    "\n",
    "    data[\"wait_times\"].append(time_start_process - time_at_queue)\n",
    "    data[\"process_times\"].append(time_end_process - time_start_process)\n",
    "\n",
    "def setup(env, init, data):\n",
    "    INIT_TASKS = init[0]\n",
    "    N_MACHINES = init[1]\n",
    "\n",
    "    MARKOV_TASK_DURATION = init[2]\n",
    "    MARKOV_TASK_ARRIVAL = init[3]\n",
    "    shortest_job_first = init[4]\n",
    "    time_choice = init[5]\n",
    "\n",
    "    server = Server(env, N_MACHINES)\n",
    "    waiting_times = []\n",
    "\n",
    "    for i in range(INIT_TASKS):\n",
    "        env.process(process_task(env, server, data, waiting_times, MARKOV_TASK_DURATION, shortest_job_first, time_choice))\n",
    "\n",
    "    while True:\n",
    "        yield env.timeout(generate_random_markov(MARKOV_TASK_ARRIVAL))\n",
    "        i += 1\n",
    "        # if server.queue_length > 0:\n",
    "        #     print(server.machine.queue)\n",
    "        env.process(process_task(env, server, data, waiting_times, MARKOV_TASK_DURATION, shortest_job_first, time_choice))\n",
    "\n",
    "\n",
    "def generate_random_markov(lamda):\n",
    "    \"\"\"\n",
    "    Markov CDF: y = 1 - e^(-lamda t)\n",
    "    The y value has a range of 0 to 1, which we can sample.\n",
    "    Thus we can obtain a random t value by sampling y\n",
    "\n",
    "    t = - ln(1 - y) / lamda\n",
    "    \"\"\"\n",
    "\n",
    "    r = random.random()\n",
    "    return -math.log(1 - r) / lamda\n",
    "\n",
    "def generate_long_tail():\n",
    "    \"\"\"\n",
    "    Generate a random number from a distribution where 75% of the jobs have an exponential distribution\n",
    "    with an average service time of 1.0 and the remaining 25% an exponential distribution\n",
    "    with an average service time of 5.0.\n",
    "\n",
    "    The average of the exponential distribution is 1 / lamda. Thus lamda = 1 / expectation.\n",
    "    \"\"\"\n",
    "\n",
    "    r = random.random()\n",
    "    \n",
    "    if r < 0.75:\n",
    "        lamda = 1 / 1\n",
    "    else:\n",
    "        lamda = 1 / 5\n",
    "    \n",
    "    return generate_random_markov(lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(init, printing=False):\n",
    "    data = {\n",
    "    \"wait_times\": [],\n",
    "    \"process_times\": [],\n",
    "    }\n",
    "    env = simpy.Environment()\n",
    "    env.process(setup(env, init, data))\n",
    "    env.run(until=MAX_SIM_TIME)\n",
    "    \n",
    "    avg_wait_time = np.mean(data[\"wait_times\"])\n",
    "    avg_process_time = np.mean(data[\"process_times\"])   \n",
    "    \n",
    "    if printing:\n",
    "        print(f\"Avg wait time: {avg_wait_time}\")\n",
    "        print(f\"Avg process time: {avg_process_time}\")\n",
    "    \n",
    "    return avg_wait_time, avg_process_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest job first:\n",
      "Avg wait time: 3.3880140278064848\n",
      "Avg process time: 0.999732802479613\n",
      "First in first out:\n",
      "Avg wait time: 12.378646950130632\n",
      "Avg process time: 1.006414015478233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12.378646950130632, 1.006414015478233)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INIT_TASKS = 4\n",
    "N_MACHINES = 1\n",
    "MAX_SIM_TIME = 10000\n",
    "\n",
    "MARKOV_TASK_DURATION = 1\n",
    "MARKOV_TASK_ARRIVAL = 0.9\n",
    "shortest_job_first = True\n",
    "time_choice = 'm'\n",
    "\n",
    "init = [INIT_TASKS, N_MACHINES, MARKOV_TASK_DURATION, MARKOV_TASK_ARRIVAL, shortest_job_first, time_choice]\n",
    "\n",
    "print(\"Shortest job first:\")\n",
    "run(init, True)\n",
    "\n",
    "shortest_job_first = False\n",
    "\n",
    "init = [INIT_TASKS, N_MACHINES, MARKOV_TASK_DURATION, MARKOV_TASK_ARRIVAL, shortest_job_first, time_choice]\n",
    "\n",
    "print(\"First in first out:\")\n",
    "run(init, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest job first:\n",
      "Avg wait time: 1.484368161226573\n",
      "Avg process time: 0.9983168589023531\n",
      "First in first out:\n",
      "Avg wait time: 4.299720191826096\n",
      "Avg process time: 0.9996351574812468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.299720191826096, 0.9996351574812468)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INIT_TASKS = 4\n",
    "N_MACHINES = 2\n",
    "MAX_SIM_TIME = 10000\n",
    "\n",
    "MARKOV_TASK_DURATION = 1\n",
    "MARKOV_TASK_ARRIVAL = 1.8\n",
    "shortest_job_first = True\n",
    "\n",
    "init = [INIT_TASKS, N_MACHINES, MARKOV_TASK_DURATION, MARKOV_TASK_ARRIVAL, shortest_job_first, time_choice]\n",
    "\n",
    "print(\"Shortest job first:\")\n",
    "run(init, True)\n",
    "\n",
    "shortest_job_first = False\n",
    "\n",
    "init = [INIT_TASKS, N_MACHINES, MARKOV_TASK_DURATION, MARKOV_TASK_ARRIVAL, shortest_job_first, time_choice]\n",
    "\n",
    "print(\"First in first out:\")\n",
    "run(init, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest job first:\n",
      "Avg wait time: 4.791936435399111\n",
      "Avg process time: 1.0\n",
      "First in first out:\n",
      "Avg wait time: 4.414458028562566\n",
      "Avg process time: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.414458028562566, 1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INIT_TASKS = 4\n",
    "N_MACHINES = 1\n",
    "MAX_SIM_TIME = 100000\n",
    "\n",
    "MARKOV_TASK_DURATION = 1\n",
    "MARKOV_TASK_ARRIVAL = 0.9\n",
    "shortest_job_first = True\n",
    "time_choice = 'd'\n",
    "\n",
    "init = [INIT_TASKS, N_MACHINES, MARKOV_TASK_DURATION, MARKOV_TASK_ARRIVAL, shortest_job_first, time_choice]\n",
    "\n",
    "print(\"Shortest job first:\")\n",
    "run(init, True)\n",
    "\n",
    "shortest_job_first = False\n",
    "\n",
    "init = [INIT_TASKS, N_MACHINES, MARKOV_TASK_DURATION, MARKOV_TASK_ARRIVAL, shortest_job_first, time_choice]\n",
    "\n",
    "print(\"First in first out:\")\n",
    "run(init, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "5\n",
      "10\n",
      "20\n",
      "[[9.87734334615913, 9.7525522626471, 9.643496600760619, 9.263994117448824, 9.72413991322308, 9.86597248706892, 9.365991272650461, 9.065913949752666, 7.963712902629005, 9.156675208421115], [4.085698979385603, 4.414662620228154, 4.415292674091484, 4.152824156503135, 4.157622690583137, 3.9652593449910634, 4.638718836218098, 4.186074182482078, 3.9344366964274227, 4.169169264126931], [1.5730620540506155, 1.5030286297131, 1.4841192565918193, 1.5131847626937553, 1.4764525839924059, 1.5342087766924417, 1.6450164999645978, 1.6243263928344565, 1.5451390359846884, 1.5264747087700234], [0.6657927810874119, 0.6678139280257962, 0.6611281661563772, 0.6452718633456183, 0.6706162081681911, 0.6509280162837966, 0.7067482169080457, 0.6813914466656514, 0.6910980541453653, 0.6715922374006306], [0.2828761043454637, 0.26590488618036673, 0.2778350307662947, 0.28072034613841557, 0.2712376165345898, 0.27383859138622957, 0.2723970601792229, 0.2780432648712529, 0.2773908419681072, 0.2540670749815318]]\n"
     ]
    }
   ],
   "source": [
    "waiting_time_list = []\n",
    "for N_MACHINES in [1, 2, 5, 10, 20]:\n",
    "    print(N_MACHINES)\n",
    "    waiting_time_list.append([])\n",
    "    for _ in range(10):\n",
    "        INIT_TASKS = 4\n",
    "        MAX_SIM_TIME = 100000\n",
    "\n",
    "        MARKOV_TASK_DURATION = 1\n",
    "        MARKOV_TASK_ARRIVAL = 0.9 * N_MACHINES\n",
    "        shortest_job_first = False\n",
    "        time_choice = 'm'\n",
    "\n",
    "        init = [INIT_TASKS, N_MACHINES, MARKOV_TASK_DURATION, MARKOV_TASK_ARRIVAL, shortest_job_first, time_choice]\n",
    "\n",
    "        result = run(init)\n",
    "\n",
    "        waiting_time_list[-1].append(result[0])\n",
    "\n",
    "print(waiting_time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 9.367979206076091\n",
      "standard deviation 0.5455986945623932\n",
      "average: 4.2119759445037115\n",
      "standard deviation 0.20671927502984586\n",
      "average: 1.5425012701287906\n",
      "standard deviation 0.05353474935744028\n",
      "average: 0.6712380918186885\n",
      "standard deviation 0.017289652840303062\n",
      "average: 0.27343108173514746\n",
      "standard deviation 0.007977113892037375\n"
     ]
    }
   ],
   "source": [
    "for result in waiting_time_list:\n",
    "    print(\"average:\",np.mean(result))\n",
    "    print(\"standard deviation\",np.std(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pvalue(data1, data2):\n",
    "    \"\"\"Calculates the pvalue for two data sets. \"\"\"\n",
    "\n",
    "    return scipy.stats.ttest_ind(data1, data2).pvalue\n",
    "\n",
    "def plot_rho_significance(xs, ys, ci):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs,ys)\n",
    "    ax.fill_between(xs, ys - ci, ys + ci, color='b', alpha=.1)\n",
    "    ax.set_xlabel(\"rho\")\n",
    "    ax.set_ylabel(\"# experiments\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def calc_plot_data(rhos, lamda, nruns):\n",
    "\n",
    "    data = []\n",
    "    for _ in range(nruns):\n",
    "\n",
    "        results = calc_rho_significance(rhos, lamda)\n",
    "        data.append(results)\n",
    "\n",
    "    data = np.array(data)\n",
    "    y_averages = np.mean(data, axis=0)\n",
    "    y_std = np.std(data, axis=0)\n",
    "\n",
    "    return y_averages, y_std\n",
    "\n",
    "def calc_rho_significance(rhos, lamda):\n",
    "    \"\"\"\n",
    "    Will look into how many experiments are needed to have significant difference \n",
    "    between multiple configurations. And how this depends on rho\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    for rho in rhos:\n",
    "        results.append(n_experiments(rho, lamda))\n",
    "\n",
    "    return results\n",
    "\n",
    "    print(rhos)\n",
    "    print(results)\n",
    "    \n",
    "    plt.xlabel(\"rho\")\n",
    "    plt.ylabel(\"# experiments\")\n",
    "    plt.plot(rhos, results)\n",
    "    plt.show()\n",
    "\n",
    "def n_experiments(rho, lamda):\n",
    "\n",
    "    p_significance = 0.05\n",
    "    max_counter = 10000\n",
    "\n",
    "    datas = [[], [], []]\n",
    "    counter = 0\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        datas[0] += generate_data(rho, lamda, 1, 1)\n",
    "        datas[1] += generate_data(rho, lamda, 2, 1)\n",
    "        datas[2] += generate_data(rho, lamda, 4, 1)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        # If counter is 1 then there is only one data point for each configuration.\n",
    "        # There is no way to perform a ttest with one data point\n",
    "        if counter == 1:\n",
    "            continue\n",
    "\n",
    "        # Calc p value for each combination of the data sets\n",
    "        pvalue01 = calc_pvalue(datas[0], datas[1])\n",
    "        pvalue02 = calc_pvalue(datas[0], datas[2])\n",
    "        pvalue12 = calc_pvalue(datas[1], datas[2])\n",
    "\n",
    "        print(f\"\\r{rho:.2f}, {counter}, {pvalue01}, {pvalue02}, {pvalue12}\", end=\"\")\n",
    "        if pvalue01 < p_significance and pvalue02 < p_significance and pvalue12 < p_significance:\n",
    "            print(\"\")\n",
    "            return counter\n",
    "\n",
    "        if counter >= max_counter:\n",
    "            print(\"WARNING: terminating early\")\n",
    "            return max_counter\n",
    "\n",
    "def generate_data(rho, lamda, n_machines, nruns):\n",
    "\n",
    "    # Calculate the server capacity needed to achieve an average server load of rho\n",
    "    mu = lamda / (n_machines * rho)\n",
    "\n",
    "    data = []\n",
    "    for i in range(nruns):\n",
    "        \n",
    "        # Each machine is initialized with 1 task\n",
    "        # The expectation value for the arrival rate is lamda \n",
    "        # thus the parameter is 1 / lamda.\n",
    "        # The average task duration is 1/mu. Thus the task duration parameter is\n",
    "        # 1/(1/mu) = mu\n",
    "        parameters = [n_machines, n_machines, mu, 1/lamda, False, \"m\"]\n",
    "        results = run(parameters)\n",
    "        data.append(results[0])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_SIM_TIME = 10000\n",
    "# rhos = np.linspace(0.1, 0.8, 10)\n",
    "\n",
    "# ys, ci = calc_plot_data(rhos, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_rho_significance(rhos, ys, ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_compare_mmn_data(rho, lamda, nruns):\n",
    "\n",
    "    data1 = generate_data(rho, lamda, 1, nruns)\n",
    "    data2 = generate_data(rho, lamda, 2, nruns)\n",
    "    data4 = generate_data(rho, lamda, 4, nruns)\n",
    "\n",
    "    return data1, data2, data4\n",
    "\n",
    "def plot_compare_mnn(data, labels):\n",
    "\n",
    "    plt.boxplot(data, labels=labels)\n",
    "    plt.ylabel(\"Average waiting time\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SIM_TIME = 10000\n",
    "data = calculate_compare_mmn_data(0.7, 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUj0lEQVR4nO3df5Afd33f8eeLQ1QJxkaKFBpsiAgFcnBAoAchQZlYIQXjGJikgaAmpDhH3ZkSDabQ0M5RbEI0nQZIIabECOSakHDEA5QYBgJpcrG5AJ2cgGKBGsbBBQwkFli1PVCFs3j3j+9XjjD3YyV997t3t8/HzHfuvrt73+9r/IXvS7uf3f2kqpAk9dd9ug4gSeqWRSBJPWcRSFLPWQSS1HMWgST13H27DnC6duzYUbt27eo6hiRtKIcOHfp6Ve1cbt2GK4Jdu3axuLjYdQxJ2lCSfHGldR4akqSeswgkqecsAknqOYtAknrOIpCknrMI1om5uTmmpqaYmJhgamqKubm5riNJ6okNd/roZjQ3N8fs7CwHDx5k9+7dLCwsMDMzA8DevXs7Tidps8tGuw319PR0bbbrCKamprjqqqvYs2fPPcvm5+fZt28fhw8f7jCZpM0iyaGqml52nUXQvYmJCY4fP86WLVvuWba0tMTWrVs5ceJEh8kkbRarFYFjBOvA5OQkCwsL37VsYWGBycnJjhJJ6hOLYB2YnZ1lZmaG+fl5lpaWmJ+fZ2ZmhtnZ2a6jSeoBB4vXgZMDwvv27ePIkSNMTk6yf/9+B4oljYVjBJLUA44RSJJWZBFIUs9ZBJLUcxaBJPWcRSBJPWcRSFLPWQSS1HMWgST1nEUgST1nEUhSz7VWBEmuSXJbkmVvqJ/kvCTvT/K/knw2yaVtZZEkrazNPYJrgYtWWf9i4HNV9XjgQuD1Se7XYh5J0jJaK4KquhG4fbVNgAckCXDOcNu728ojSVpel2MEbwImga8CNwEvqarvLLdhksuSLCZZPHr06DgzStKm12URPAP4NPBg4MeANyU5d7kNq+pAVU1X1fTOnTvHl1CSeqDLIrgUeG8N3AzcAvxoh3kkqZe6LIIvAU8DSPIg4FHAFzrMI0m91NpUlUnmGJwNtCPJrcAVwBaAqroaeA1wbZKbgACvqKqvt5VHkrS81oqgqladcLeqvgo8va33lyQ145XF0gjMzc0xNTXFxMQEU1NTzM3NdR1Jaqy1PQItb3DZxNmpqhEk0ajMzc0xOzvLwYMH2b17NwsLC8zMzACwd++qO8bSupCN9qUyPT1di4uLXcdoTRK/6DeYqakprrrqKvbs2XPPsvn5efbt28fhw8veYUUauySHqmp62XUb7UvHItB6MzExwfHjx9myZcs9y5aWlti6dSsnTpzoMJn0D1YrAscIpLM0OTnJwsLCdy1bWFhgcnKyo0TS6bEIpLM0OzvLzMwM8/PzLC0tMT8/z8zMDLOzs11HkxpxsFg6SycHhPft28eRI0eYnJxk//79DhRrw3CMYJ1xjEBSGxwjkCStyCKQpJ6zCCSp5ywCSeo5i0CSes4ikKSeswgkqecsAknqOYtAknrOIpCknrMIJKnnLIIR2r59O0nO6gGc9Wts37694/8SkjYS7z46QseOHVsXN4wbxXSYkvrDPQJJ6jmLQJJ6ziKQpJ5bswiSPCjJwSQfGj5/dJKZ9qNJksahyR7BtcCHgQcPn38euLylPJKkMWtSBDuq6jrgOwBVdTdwYq0/SnJNktuSHF5lmwuTfDrJZ5Pc0Di1JGlkmhTBN5P8AFAASZ4C3NHg764FLlppZZIHAm8Gnl1VjwGe2+A1JUkj1uQ6gn8LXA88PMlfAjuBX1zrj6rqxiS7VtnkXwDvraovDbe/rUEWSdKIrVkEVfXJJD8NPAoI8NdVtTSC934ksCXJXwAPAN5YVb+/3IZJLgMuA3joQx86greWJJ20ZhEkmQAuBnYNt396Eqrqd0bw3v8UeBrwfcDHk3yiqj5/7w2r6gBwAGB6err7S3dXUFecC1ee13WMQQ5JaqjJoaH3A8eBmxgOGI/IrcA3quqbDMYhbgQez+CspA0pr75z3dxioq7sOoWkjaJJEVxQVY9r4b3/GHhTkvsC9wN+HPgvLbyPJGkVTYrgQ0meXlUfOZ0XTjIHXAjsSHIrcAWwBaCqrq6qI0n+BPgMgz2Nt1XViqeaSpLa0aQIPgH89yT3AZYYDBhXVa16ILqq9q71wlX1WuC1TYJKktrRpAh+B/gJ4KZaDwfAJUkj1eSCsi8Dhy0BSdqcmuwRfAH4i+FN5/7+5MIRnD4qSVoHmhTBLcPH/YYPSdIm0uTK4lePI8hmsR6midy2bVvXETalUX22HmXVerNiESR5Q1VdnuT9DG84d6qqenaryTagUfwffHjV9gjSaNSafC5+ftqIVtsjeMfw5+vGEUSS1I0Vi6CqDg1//bGqeuOp65K8BHD+AEnaBJqcPvovl1n2whHnkCR1ZLUxgr0M5gx4WJLrT1n1AOD2toNJksZjtTGCjwFfA3YArz9l+V0M7g8kSdoEVhsj+CLwRQa3l5AkbVJNxggkSZuYRSBJPdfkFhMaoSZXp661jRcsSRqlJnMW38T3Xll8B7AI/FZVfaONYJuVX+KS1ptGM5QBJ4B3Dp8/H/h+4G+Ba4FntZJMkjQWTYrgZ6vqiac8vynJJ6vqiUl+pa1gkqTxaDJYPJHkySefJHkSMDF8encrqSRJY9Nkj+BFwDVJzmEwX/GdwIuS3B/4T22GkyS1r8l8BH8FPDbJecPnd5yy+rq2gkmSxqPJWUP/CPjnwC7gvidPbayq32w1mSRpLJocGvpjBqeLHuKUOYslSZtDkyK4oKouaj2JJKkTTc4a+liSx7aeROrY9u3bSXJWD+Cs/n779u0d/1dQHzXZI9gNvDDJLQwODQWoqnpcq8mkMTt27FjnV343uQWJNGpNiuCZZ/LCSa4BLgFuq6qpVbZ7EvBx4PlV9e4zeS9J0plb8dBQknOHv961wmMt1wKrji0kmQD+M/CRBq8nSWrBansE72TwL/pDDG46d+o+awE/stoLV9WNSXat8f77gPcAT1ozqSSpFavNUHbJ8OfD2njjJOcDPw/swSKQpM6sedZQkj9rsuwMvAF4RVV9p0GGy5IsJlk8evToCN5aknTSinsESbYyuN30jiTb+IdDQ+cC54/gvaeBdw3PktgBXJzk7qp63703rKoDwAGA6elpb+gvSSO02hjBvwYuBx4MfPKU5XcCbzrbNz71kFOSa4EPLFcCkqR2rTZG8EbgjUn2VdVVp/vCSeaACxnsUdwKXAFsGb721WcWV5I0aqsdGvqZqvpz4CtJfuHe66vqvau9cFXtbRqiql7YdFtJ0mitdmjop4E/Z/mpKAtYtQgkSRvDaoeGrhj+vHR8cSRJ49bkFhMk+TngMcDWk8ucj0CSNocm1xFcDfwSg6uAAzwX+OGWc0mSxqTJbah/sqp+FThWVa8GfgJ4ZLuxJEnj0qQI/t/w57eSPBhYAn6ovUiSpHFqMkbwgSQPBF7L4MKyAt7aZqg+mpubY//+/Rw5coTJyUlmZ2fZu7fxGbgagbriXLjyvO4zSGO2ZhFU1WuGv74nyQeArVV1R7ux+mVubo7Z2VkOHjzI7t27WVhYYGZmBsAyGKO8+s51MTFNXdlpBPVQ1voffpIF4Abgo8BfVlWTuQhaMz09XYuLi11GGLmpqSmuuuoq9uzZc8+y+fl59u3bx+HDhztM1i9J1kcRdJxBm1OSQ1U1vey6BkXwMOCnho+nMJiu8qNV9dJRB21iMxbBxMQEx48fZ8uWLfcsW1paYuvWrZw4caLDZP2yHr6E10MGbU6rFcGag8VVdQvwp8CfATcyuCPp5EgT9tzk5CQLCwvftWxhYYHJSf8zS2pfk+sI/gZ4H/Ag4CAwVVWrTkGp0zM7O8vMzAzz8/MsLS0xPz/PzMwMs7OzXUeT1ANNzhr6XWA3sBd4AnBDkhur6m9aTdYjJweE9+3bd89ZQ/v373egWNJYrDlGcM+GyTnApcDLgQuqaqLNYCvZjGMEWh/Ww/H59ZBBm9NqYwRr7hEkeT2DPYJzgI8Br2JwBpEkaRNocmjo48BvV9XftR1G6tpw6tTObNu2rdP3Vz81uaDs3eMIInVtFIdkPLSjjajJvYYkSZuYRSBJPdeoCJLsTnLp8Pedw6uNJUmbQJMLyq4AXgH8h+GiLcAftBlKkjQ+TfYIfh54NvBNgKr6KvCANkNJksanSRF8uwanQRRAkvu3G0mSNE5NriO4LslbgAcm+VfAr+HENJI2mFFdI7IZTw9uch3B65L8M+BO4FHAq6rqT1tPJkkj1OCW+5vyS76JJnsEDL/4/fKXpE2oyb2G7mI4PnCKO4BF4GVV9YU2gkmSxqPJYPEbgH8HnA9cwODuo+8E3gVcs9IfJbkmyW1Jlp1rMckvJ/lMkpuSfCzJ4087vSTprDUpgmdX1Vuq6q6qurOqDgDPqKo/Ala7Q9a1wGoT2NwC/HRVPRZ4DXCgaWhJ0ug0KYJvJXlekvsMH88Djg/XrTiyUlU3Arevsv5jVXVs+PQTDPY2JElj1qQIfhl4AXAb8HfD338lyfcBvz6iHDPAh1ZameSyJItJFo8ePTqit5QkQbPTR78APGuF1QsrLG8syR4GRbB7lQwHGB46mp6e7uf5XZLUkiZnDW1l8EX9GGDryeVV9Wtn++ZJHge8DXhmVX3jbF9PknT6mhwaegfwj4FnADcwOJZ/19m+cZKHAu8FXlBVnz/b15MknZkmF5T9k6p6bpLnVNXbk7yTBnMWJ5kDLgR2JLkVuILBnUupqqsZzH38A8Cbh5d+373SxMqSpPY0KYKl4c//m2QK+FvgB9f6o6rau8b6FwEvavD+kqQWNSmCA0m2Aa8ErgfOAf5jq6kkSWOzahEkuQ9w5/B8/xuBHxlLKknS2Kw6WFxV3wF+Y0xZJEkdaHLW0P9I8vIkD0my/eSj9WSSpLFoMkbwS8OfLz5lWeFhIknaFJpcWfywcQSRJHVjzUNDSb4/ySuTHBg+f0SSS9qPJkkahyZjBP8N+Dbwk8PnXwF+q7VEkqSxalIED6+q32Z4YVlVfQsYzSzQkqTONRks/vbwltMFkOThwN+3mkpah4a3Qjnr7fo6QbrWryZFcCXwJ8BDkvwh8FTghS1mktYlv8C1WTU5a+gjSQ4BT2FwSOglVfX11pNJksaiyXwE72cwWf31VfXN9iNJksapyWDx64CfAj6X5N1JfnE4WY0kaRNYswiq6oaq+jcMriR+C/A8BvMXS9K6sH37dpKc1QM469fYvn1j3n2nyWAxw7OGnsXgdhNPBN7eZihJOh3Hjh1bF4P5Tc8sW2+ajBFcBzyZwZlDbwJuGN6VVJK0CTTZIzgI7K2qEwBJdifZW1UvXuPvJEkbQJPTRz+c5AlJ9jIYH7iFwaTzkqRNYMUiSPJIYO/w8XXgj4BU1Z4xZZMkjcFqewT/G/gocElV3QyQ5KVjSSVJGpvVTh/9BeBrwHyStyZ5Gt5sTpI2nRWLoKreV1XPB34UmAcuB34wye8lefqY8kmSWtbkgrJvVtU7q+pZwAXAp4BXtJ5MkjQWTW4xcY+qOlZVB6rqaW0FkiSN12kVgSRp82mtCJJck+S2JIdXWJ8kv5vk5iSfSfLEtrJIklbW5h7BtcBFq6x/JvCI4eMy4PdazCJJWkFrRVBVNwK3r7LJc4Dfr4FPAA9M8kNt5ZEkLa/LMYLzgS+f8vzW4bLvkeSyJItJFo8ePTqWcJLUFxtisHh4ptJ0VU3v3Lmz6ziStKl0WQRfAR5yyvMLhsskSWPUZRFcD/zq8OyhpwB3VNXXOswjSb3UaIayM5FkDrgQ2JHkVuAKYAtAVV0NfBC4GLgZ+BZwaVtZJEkra60IqmrvGusLcHIbSepYa0UgSeNSV5wLV57XdYxBjg3IIpC04eXVd66byevryq5TnL4NcfqoJKk9FoEk9ZxFIEk9ZxFIUs9ZBJLUcxaBJPWcRSBJPWcRSFLPWQSS1HNeWSxpU0jSdQS2bdvWdYQzYhFI2vBGcXuJJOviNhVd8NCQJPWcRSBJPWcRSFLPWQSS1HMWgST1nEUgST1nEUhSz1kEktRzFoEk9ZxFIEk9ZxFIUs9ZBJLUcxaBJPVcq0WQ5KIkf53k5iT/fpn1D00yn+RTST6T5OI280iSvldrRZBkAvivwDOBRwN7kzz6Xpu9Eriuqp4APB94c1t5JEnLa3OP4MnAzVX1har6NvAu4Dn32qaAc4e/nwd8tcU8kqRltDkxzfnAl095fivw4/fa5krgI0n2AfcHfrbFPJKkZXQ9WLwXuLaqLgAuBt6R5HsyJbksyWKSxaNHj449pCRtZm0WwVeAh5zy/ILhslPNANcBVNXHga3Ajnu/UFUdqKrpqpreuXNnS3ElqZ/aLIK/Ah6R5GFJ7sdgMPj6e23zJeBpAEkmGRSB/+SXpDFqbYygqu5O8uvAh4EJ4Jqq+myS3wQWq+p64GXAW5O8lMHA8Qurr7NHS2pVkpFssxm/otocLKaqPgh88F7LXnXK758DntpmBkmCzfkFPipdDxZLkjpmEUhSz1kEktRzFoEk9ZxFIEk9ZxFIUs9ZBJLUcxaBJPVcNtpFFkmOAl/sOkeLdgBf7zqEzpif38a12T+7H66qZW/WtuGKYLNLslhV013n0Jnx89u4+vzZeWhIknrOIpCknrMI1p8DXQfQWfHz27h6+9k5RiBJPecegST1nEUgST1nEawTSa5JcluSw11n0elJ8pAk80k+l+SzSV7SdSadviQTST6V5ANdZxk3i2D9uBa4qOsQOiN3Ay+rqkcDTwFenOTRHWfS6XsJcKTrEF2wCNaJqroRuL3rHDp9VfW1qvrk8Pe7GHyZnN9tKp2OJBcAPwe8ressXbAIpBFKsgt4AvA/O46i0/MG4DeA73ScoxMWgTQiSc4B3gNcXlV3dp1HzSS5BLitqg51naUrFoE0Akm2MCiBP6yq93adR6flqcCzk/wf4F3AzyT5g24jjZcXlK0jw8MKH6iqqa6zqLkkAd4O3F5Vl3ccR2chyYXAy6vqko6jjJV7BOtEkjng48CjktyaZKbrTGrsqcALGPxL8tPDx8Vdh5Kaco9AknrOPQJJ6jmLQJJ6ziKQpJ6zCCSp5ywCSeo5i0CSes4ikKSe+/+MCNA3G5VejQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.360024604601612e-07, 2.5032099429328525e-19, 7.305240174251832e-11"
     ]
    }
   ],
   "source": [
    "plot_compare_mnn(data, [\"1\", \"2\", \"4\"])\n",
    "print(f\"{calc_pvalue(data[0], data[1])}, {calc_pvalue(data[0], data[2])}, {calc_pvalue(data[1], data[2])}\", end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
